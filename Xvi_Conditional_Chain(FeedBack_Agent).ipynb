{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFoJPSG3wnKQVBpkyjbzus",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vinayak-Sharma12/GENAI/blob/main/Xvi_Conditional_Chain(FeedBack_Agent).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CONDITIONAL CHAIN**"
      ],
      "metadata": {
        "id": "PJ-DvNxc-GRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basically it is classifier like.\n",
        "\n",
        "###If this happens go to this llm with this prompt\n",
        "\n",
        "###and Else if this happens to this llm with this prompt"
      ],
      "metadata": {
        "id": "WTy7bOcR-RKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Example - Create a app which can handle feedback seperately like if the feedback is positive it reply like tha and if negative it reply like that\n"
      ],
      "metadata": {
        "id": "hBU3t22c-uum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26WTjk_Qasnx",
        "outputId": "01977f5a-c12c-42e6-a9a9-10725299daec"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    +-------------+      \n",
            "    | PromptInput |      \n",
            "    +-------------+      \n",
            "            *            \n",
            "            *            \n",
            "            *            \n",
            "   +----------------+    \n",
            "   | PromptTemplate |    \n",
            "   +----------------+    \n",
            "            *            \n",
            "            *            \n",
            "            *            \n",
            "      +----------+       \n",
            "      | ChatGroq |       \n",
            "      +----------+       \n",
            "            *            \n",
            "            *            \n",
            "            *            \n",
            "+----------------------+ \n",
            "| PydanticOutputParser | \n",
            "+----------------------+ \n",
            "            *            \n",
            "            *            \n",
            "            *            \n",
            "       +--------+        \n",
            "       | Branch |        \n",
            "       +--------+        \n",
            "            *            \n",
            "            *            \n",
            "            *            \n",
            "    +--------------+     \n",
            "    | BranchOutput |     \n",
            "    +--------------+     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### REQUIRED THINGS :\n",
        "                      1. Pydantic Output Parser -> So that first llm can only output postive or negative (about feedback)\n",
        "                      2. Runnable Branch -> Helps to create Conditional Logic\n",
        "                      3. Runnable Lambda->let yous to define if and else"
      ],
      "metadata": {
        "id": "2OyRanJL_JSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_groq langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEF7yqsDAe8P",
        "outputId": "e5489006-0731-48f8-a97e-813e9036101e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.50)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.23)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.22.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.49 (from langchain)\n",
            "  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.13.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.22.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, groq, dataclasses-json, langchain-core, langchain-text-splitters, langchain_groq, langchain, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.50\n",
            "    Uninstalling langchain-core-0.3.50:\n",
            "      Successfully uninstalled langchain-core-0.3.50\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.7\n",
            "    Uninstalling langchain-text-splitters-0.3.7:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.7\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.22\n",
            "    Uninstalling langchain-0.3.22:\n",
            "      Successfully uninstalled langchain-0.3.22\n",
            "Successfully installed dataclasses-json-0.6.7 groq-0.22.0 httpx-sse-0.4.0 langchain-0.3.23 langchain-core-0.3.51 langchain-text-splitters-0.3.8 langchain_community-0.3.21 langchain_groq-0.3.2 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "llm=ChatGroq(model='llama-3.1-8b-instant',api_key='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')"
      ],
      "metadata": {
        "id": "ShCM0mx1BAts"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel,Field\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableBranch,RunnableLambda\n",
        "from typing import Literal"
      ],
      "metadata": {
        "id": "OnFmAyNoBUSD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PARSER READY"
      ],
      "metadata": {
        "id": "FK2l08mPEacV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser1=StrOutputParser()"
      ],
      "metadata": {
        "id": "b2RgF_yvEWaR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class feedback(BaseModel):\n",
        "  sentiment:Literal['positive','negative']=Field(description='Give the sentiment')\n",
        "\n",
        "parser2=PydanticOutputParser(pydantic_object=feedback)"
      ],
      "metadata": {
        "id": "2MUri38ADa03"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROMPTS"
      ],
      "metadata": {
        "id": "Wg21MFcaEcAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = PromptTemplate(\n",
        "    template=\"Classify the sentiment of the following feedback text into postive or negative \\n {feedback} \\n {format_instruction}\",\n",
        "    input_variables=['text'],\n",
        "    partial_variables={'format_instruction': parser2.get_format_instructions()}\n",
        ")\n"
      ],
      "metadata": {
        "id": "hMaou9moEJex"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_chain=prompt1|llm|parser2"
      ],
      "metadata": {
        "id": "xad9Uha4GDQ9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTING PURPOSE"
      ],
      "metadata": {
        "id": "KuhQfROcGSn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\"this is the worst phone ever I  have seen\"\"\"\n",
        "result=classifier_chain.invoke(text)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I11rhP1MGT8H",
        "outputId": "4f452c57-0935-4a7d-cea2-fb738f5922ed"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feedback(sentiment='negative')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing Done"
      ],
      "metadata": {
        "id": "G1JVqZkCHREf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2=PromptTemplate(\n",
        "    template=\"Write a appropriate response for positve feedback {text}\",\n",
        "    input_variables=['text']\n",
        ")\n",
        "prompt3=PromptTemplate(\n",
        "    template=\"Write a appropriate response for negative feedback {text}\",\n",
        "    input_variables=['text']\n",
        ")"
      ],
      "metadata": {
        "id": "SG0_tnjqHSwT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "branch_chain = RunnableBranch(\n",
        "    (lambda x:x.sentiment == 'positive', prompt2 | llm | parser1),\n",
        "    (lambda x:x.sentiment == 'negative', prompt3 | llm | parser1),\n",
        "    RunnableLambda(lambda x: \"could not find sentiment\")\n",
        ")"
      ],
      "metadata": {
        "id": "_JQka-RhHzuD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = classifier_chain | branch_chain\n",
        "\n",
        "print(chain.invoke(\"This is best phone ever\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhsq_dn4H7_5",
        "outputId": "18a2b8ec-86d0-4669-e3ab-da09b7a46cff"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Thank you so much for your kind words! I'm thrilled to hear that you're happy with the outcome. I appreciate your feedback and will continue to strive for excellence in my work.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GET GRAPH**"
      ],
      "metadata": {
        "id": "yw5iBuptaXAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grandalf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qla36RF0ajyI",
        "outputId": "2f95ea5e-522b-4765-cb5f-de23baf0fa3c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting grandalf\n",
            "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from grandalf) (3.2.3)\n",
            "Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: grandalf\n",
            "Successfully installed grandalf-0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL0z_-N8aaSl",
        "outputId": "93396597-10bc-4261-908f-81b3acbffa3d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    +-------------+      \n",
            "    | PromptInput |      \n",
            "    +-------------+      \n",
            "            *            \n",
            "            *            \n",
            "            *            \n",
            "   +----------------+    \n",
            "   | PromptTemplate |    \n",
            "   +----------------+    \n",
            "            *            \n",
            "            *            \n",
            "            *            \n",
            "      +----------+       \n",
            "      | ChatGroq |       \n",
            "      +----------+       \n",
            "            *            \n",
            "            *            \n",
            "            *            \n",
            "+----------------------+ \n",
            "| PydanticOutputParser | \n",
            "+----------------------+ \n",
            "            *            \n",
            "            *            \n",
            "            *            \n",
            "       +--------+        \n",
            "       | Branch |        \n",
            "       +--------+        \n",
            "            *            \n",
            "            *            \n",
            "            *            \n",
            "    +--------------+     \n",
            "    | BranchOutput |     \n",
            "    +--------------+     \n"
          ]
        }
      ]
    }
  ]
}